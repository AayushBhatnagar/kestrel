<html>
<head>
<style type="text/css">

body {
  padding: 1em 1em 1em 2em;
  background: #ebeaff;
  font-family: Geneva, Helvetica, sans-serif;
  color: #142524;
}

h1 {
  color: #42525B;
  font-size: 150%;
}

h2 {
  color: #42525B;
  font-size: 125%;
}

h3 {
  color: #42525B;
  font-size: 100%;
}

p, dl {
  margin-left: 2em;
  margin-right: 2em;
}

ul, ol {
  margin-left: 1em;
  margin-right: 2em;
}

ul p, ol p {
  margin-left: 0em;
  margin-right: 0em;
}

a:link, a:visited {
  color: #630E08;
  text-decoration: none;
  font-weight: bold;
}

a:active {
  color: #142524;
  text-decoration: none;
  font-weight: bold;
}

ul li {
  display: list-item;
  list-style-type: disc;
}

pre {
  margin-left: 2.5em;
  margin-right: 6em;
  padding: 1em;
  background: #efecca;
  border: 1px dotted #a7a37e;
}

code {
  font-weight: bold;
}

pre code {
  font-weight: normal;
}

table {
  border-collapse: collapse;
}

table, th, td {
  border: 1px solid black;
  text-align: left;
  padding: 0.5em;
}
</style>
</head>

<body>

<h1>A working guide to kestrel</h1>

<p>Kestrel is a very simple message queue that runs on the JVM. It supports
multiple protocols:</p>

<ul>
<li>memcache: the memcache protocol, with some extensions</li>
<li>thrift: Apache Thrift-based RPC</li>
<li>text: a simple text-based protocol</li>
</ul>

<p>A single kestrel server has a set of queues identified by a name, which is
also the filename of that queue's journal file (usually in
<code>/var/spool/kestrel</code>). Each queue is a strictly-ordered FIFO of "items" of
binary data. Usually this data is in some serialized format like JSON or
ruby's marshal format.</p>

<p>Generally queue names should be limited to alphanumerics <code>[A-Za-z0-9]</code>, dash
(<code>-</code>) and underline (<code>_</code>). In practice, kestrel doesn't enforce any
restrictions other than the name can't contain slash (<code>/</code>) because that can't
be used in filenames, squiggle (<code>~</code>) because it's used for temporary files,
plus (<code>+</code>) because it's used for fanout queues, and dot (<code>.</code>) because it's
reserved for future use. Queue names are case-sensitive, but if you're running
kestrel on OS X or Windows, you will want to refrain from taking advantage of
this, since the journal filenames on those two platforms are <em>not</em>
case-sensitive.</p>

<p>A cluster of kestrel servers is like a memcache cluster: the servers don't
know about each other, and don't do any cross-communication, so you can add as
many as you like. The simplest clients have a list of all servers in the
cluster, and pick one at random for each operation. In this way, each queue
appears to be spread out across every server, with items in a loose ordering.
More advanced clients can find kestrel servers via ZooKeeper.</p>

<p>When kestrel starts up, it scans the journal folder and creates queues based
on any journal files it finds there, to restore state to the way it was when
it last shutdown (or was killed or died). New queues are created by referring
to them (for example, adding or trying to remove an item). A queue can be
deleted with the "delete" command.</p>

<h2>Configuration</h2>

<p><strong>NOTE:</strong> Kestrel 2.3.4 introduces inheritance for queue configurations. For more
information, see below.</p>

<p>The config files for kestrel are scala expressions loaded at runtime, usually
from <code>production.scala</code>, although you can use <code>development.scala</code> by passing
<code>-Dstage=development</code> to the java command line.</p>

<p>The config file evaluates to a <code>KestrelConfig</code> object that's used to configure
the server as a whole, a default queue, and any overrides for specific named
queues. The fields on <code>KestrelConfig</code> are documented here with their default
values:
<a href="http://robey.github.com/kestrel/api/main/api/net/lag/kestrel/config/KestrelConfig.html">KestrelConfig</a></p>

<p>To confirm the current configuration of each queue, send "dump_config" to
a server (which can be done over telnet).</p>

<p>To reload the config file on a running server, send "reload" the same way.
You should immediately see the changes in "dump_config", to confirm. Reloading
will only affect queue and alias configuration, not global server configuration.
To change the server configuration, restart the server.</p>

<p>Logging is configured according to <code>util-logging</code>. The logging configuration
syntax is described here:
<a href="https://github.com/twitter/util/blob/master/util-logging/README.markdown">util-logging</a></p>

<p>Per-queue configuration options are documented here:
<a href="http://robey.github.com/kestrel/api/main/api/net/lag/kestrel/config/QueueBuilder.html">QueueBuilder</a></p>

<p>Queue alias configuration options are documented here:
<a href="http://robey.github.com/kestrel/api/main/api/net/lag/kestrel/config/AliasBuilder.html">AliasBuilder</a></p>

<h2>Configuration Changes Starting in Kestrel 2.3.4</h2>

<p>Starting with Kestrel 2.3.4, queue configurations are inherited:</p>

<ul>
<li>Any queue with no explict configuration (see <code>queues</code> in <code>KestrelConfig</code>) uses the default
queue configuration (see <code>default</code> in <code>KestrelConfig</code>). This behavior is unchanged from
previous versions.</li>
<li>Any master (e.g. not fanout) queue with an explicit queue configuration overrides the default
queue configuration. For example, if <code>default.maxMemorySize</code> is set, all explicitly configured
queues will inherit that setting <em>unless</em> explicitly overridden in the queue's configuration.
Older versions of Kestrel <em>did not</em> apply values from the default queue configuration to any
explicitly configured queue.</li>
<li>Any fanout queue (e.g., a queue with a <code>+</code> in its name), inherits its master queue's
configuration, unless explicitly overridden (see <code>queues</code> in <code>KestrelConfig</code>). Older versions
of Kestrel silently ignored explicit fanout queue configurations and used the master queue's
configuration.</li>
</ul>

<h3>Example Configuration</h3>

<p>Existing configurations should continue to load, but the resulting configuration may
differ. As an example, the following configuration file and table illustrate the differences
between a configuration loaded by Kestrel 2.3.3 and Kestrel 2.3.4 (and later).</p>

<pre><code>new KestrelConfig {
   default.maxMemorySize = 8.megabytes

   queues = new QueueBuilder() {
       name = "q"
       maxItems = 500
   } :: new QueueBuilder() {
       name = "q+fanout"
       maxAge = 1.minute
   } :: new QueueBuilder() {
       name = "x"
       maxMemorySize = 16.megabytes
   }
}
</code></pre>

<table>
  <tr><th>Queue</th>    <th>Setting</th>       <th>Kestrel &lt;= 2.3.3</th> <th>Kestrel &gt;= 2.3.4</th>   </tr>
  <tr><td>q</td>        <td>maxMemorySize</td> <td>128.megabytes</td>    <td>8.megabytes</td>        </tr>
  <tr><td>q+fanout</td> <td>maxMemorySize</td> <td>128.megabytes</td>    <td>8.megabytes</td>        </tr>
  <tr><td>x</td>        <td>maxMemorySize</td> <td>16.megabytes</td>     <td>16.megabytes</td>       </tr>
  <tr><td>q</td>        <td>maxItems</td>      <td>500</td>              <td>500</td>                </tr>
  <tr><td>q+fanout</td> <td>maxItems</td>      <td>500</td>              <td>500</td>                </tr>
  <tr><td>q+fanout</td> <td>maxAge</td>        <td>None</td>             <td>Some(1.minute)</td>     </tr>
</table>

<h2>Full queues</h2>

<p>A queue can have the following limits set on it:</p>

<ul>
<li><code>maxItems</code> - total items in the queue</li>
<li><code>maxSize</code> - total bytes of data in the items in the queue</li>
</ul>

<p>If either of these limits is reached, no new items can be added to the queue.
(Clients will receive an error when trying to add.) If you set
<code>discardOldWhenFull</code> to true, then all adds will succeed, and the oldest
item(s) will be silently discarded until the queue is back within the item
and size limits.</p>

<p><code>maxItemSize</code> limits the size of any individual item. If an add is attempted
with an item larger than this limit, it always fails.</p>

<h2>The journal file</h2>

<p>The journal file is the only on-disk storage of a queue's contents, and it's
just a sequential record of each add or remove operation that's happened on
that queue. When kestrel starts up, it replays each queue's journal to build
up the in-memory queue that it uses for client queries.</p>

<p>The journal file is compacted if the queue is empty and the journal is larger
than <code>defaultJournalSize</code>.</p>

<p>The current journal file is archived (or rotated) when the journal is larger
than <code>maxMemorySize</code>. In addition, if the complete journal exceeds
<code>maxJournalSize</code>, a checkpoint is set. The journal may then be compacted during
read-behind (when the size of the queue exceeds <code>maxMemorySize</code>) via the
journal packer thread.</p>

<p>For example, if <code>defaultJournalSize</code> is 16MB (the default), then if the queue
is empty and the journal is larger than 16MB, it will be compacted into a new
(empty, if there are no open transactions) file.</p>

<p>You can turn the journal off for a queue (<code>keepJournal</code> = false) and the queue
will exist only in memory. If the server restarts, all enqueued items are
lost. You can also force a queue's journal to be sync'd to disk periodically,
or even after every write operation, at a performance cost, using
<code>syncJournal</code>.</p>

<p>If a queue grows past <code>maxMemorySize</code> bytes (128MB by default), only the
first 128MB is kept in memory. The journal is used to track later items, and
as items are removed, the journal is played forward to keep 128MB in memory.
This is usually known as "read-behind" mode, but Twitter engineers sometimes
refer to it as the "square snake" because of the diagram used to brainstorm
the implementation. When a queue is in read-behind mode, removing an item will
often cause 2 disk operations instead of one: one to record the remove, and
one to read an item in from disk to keep 128MB in memory. This is the
trade-off to avoid filling memory and crashing the JVM.</p>

<h2>Item expiration</h2>

<p>When they come from a client, expiration times are handled in the same way as
memcache: if the number is small (less than one million), it's interpreted as
a relative number of seconds from now. Otherwise it's interpreted as an
absolute unix epoch time, in seconds since the beginning of 1 January 1970
GMT.</p>

<p>Expiration times are immediately translated into an absolute time, in
<em>milliseconds</em>, and if it's further in the future than the queue's <code>maxAge</code>,
the <code>maxAge</code> is used instead. An expiration of 0, which is usually the
default, means an item never expires.</p>

<p>Expired items are flushed from a queue whenever a new item is added or
removed. Additionally, if the global config option <code>expirationTimerFrequency</code>
is set, a background thread will periodically remove expired items from the
head of each queue. The provided <code>production.conf</code> sets this to one second.
If this is turned off, an idle queue won't have any items expired, but you
can still trigger a check by doing a "peek" on it.</p>

<p>Normally, expired items are discarded. If <code>expireToQueue</code> is set, then
expired items are moved to the specified queue just as if a client had put
it there. The item is added with no expiration time, but that can be
overridden if the new queue has a default expiration policy.</p>

<p>To prevent stalling the server when it encounters a swarm of items that all
expired at the same time, <code>maxExpireSweep</code> limits the number of items that
will be removed by the background thread in a single round. This is primarily
useful as a throttling mechanism when using a queue as a way to delay work.</p>

<h2>Queue expiration</h2>

<p>Whole queues can be configured to expire as well. If <code>maxQueueAge</code> is set
<code>expirationTimerFrequency</code> is used to check the queue age. If the queue is
empty, and it has been longer than <code>maxQueueAge</code> since it was created then
the queue will be deleted.</p>

<h2>Fanout Queues</h2>

<p>If a queue name has a <code>+</code> in it (like "<code>orders+audit</code>"), it's treated as a
fanout queue, using the format <code>&lt;parent&gt;+&lt;child&gt;</code>. These queues belong to a
parent queue -- in this example, the "orders" queue. Every item written into
a parent queue will also be written into each of its children.</p>

<p>Fanout queues each have their own journal file (if the parent queue has a
journal file) and otherwise behave exactly like any other queue. You can get
and peek and even add items directly to a child queue if you want. It uses the
parent queue's configuration instead of having independent child queue
configuration blocks.</p>

<p>When a fanout queue is first referenced by a client, the journal file (if any)
is created, and it will start receiving new items written to the parent queue.
Existing items are not copied over. A fanout queue can be deleted to stop it
from receiving new items.</p>

<p><code>fanoutOnly</code> may be set to true if the queue in question will only serve write
point for fanout queues.  No journal file will be kept for the parent, only
for the child queues.  This saves the overhead of writing to the parent and
removes the need to empty it.  Note that setting <code>fanoutOnly</code> to true and
having no fanouts for the queue effectively makes it a black hole.</p>

<h2>Queue Aliases</h2>

<p>Queue aliases are somewhat similar to fanout queues, but without a required
naming convention or implicit creation of child queues. A queue alias can
only be used in set operations. Kestrel responds to attempts to retrieve
items from the alias as if it were an empty queue. Delete and flush requests
are also ignored.</p>

<h2>Protocols</h2>

<p>Kestrel supports three protocols: memcache, thrift and text. The
<a href="http://twitter.github.com/finagle/">Finagle project</a> can be used to connect clients
to a Kestrel server via the memcache or thrift protocols.</p>

<h3>Thrift</h3>

<p>The thrift protocol is documented in the thrift IDL:
<a href="https://github.com/robey/kestrel/blob/master/src/main/thrift/kestrel.thrift">kestrel.thrift</a></p>

<p>Reliable reads via the thrift protocol are specified by indicating how long the server
should wait before aborting the unacknowledged read.</p>

<h3>Memcache</h3>

<p>The official memcache protocol is described here:
<a href="https://github.com/memcached/memcached/blob/master/doc/protocol.txt">protocol.txt</a></p>

<p>The kestrel implementation of the memcache protocol commands is described below.</p>

<ul>
<li><p><code>SET &lt;queue-name&gt; &lt;flags (ignored)&gt; &lt;expiration&gt; &lt;# bytes&gt;</code></p>

<p>Add an item to a queue. It may fail if the queue has a size or item limit
and it's full.</p></li>
<li><p><code>GET &lt;queue-name&gt;[options]</code></p>

<p>Remove an item from a queue. It will return an empty response immediately if
the queue is empty. The queue name may be followed by options separated
by <code>/</code>:</p>

<ul><li><p><code>/t=&lt;milliseconds&gt;</code></p>

<p>Wait up to a given time limit for a new item to arrive. If an item arrives
on the queue within this timeout, it's returned as normal. Otherwise,
after that timeout, an empty response is returned.</p></li>
<li><p><code>/open</code></p>

<p>Tentatively remove an item from the queue. The item is returned as usual
but is also set aside in case the client disappears before sending a
"close" request. (See "Reliable Reads" below.)</p></li>
<li><p><code>/close</code></p>

<p>Close any existing open read. (See "Reliable Reads" below.)</p></li>
<li><p><code>/abort</code></p>

<p>Cancel any existing open read, returing that item to the head of the
queue. It will be the next item fetched. (See "Reliable Reads" below.)</p></li>
<li><p><code>/peek</code></p>

<p>Return the first available item from the queue, if there is one, but don't
remove it. You can't combine this with any of the reliable read options.</p></li></ul>

<p>For example, to open a new read, waiting up to 500msec for an item:</p>

<pre><code>GET work/t=500/open
</code></pre>

<p>Or to close an existing read and open a new one:</p>

<pre><code>GET work/close/open
</code></pre></li>
<li><p><code>DELETE &lt;queue-name&gt;</code></p>

<p>Drop a queue, discarding any items in it, and deleting any associated
journal files.</p></li>
<li><p><code>FLUSH &lt;queue-name&gt;</code></p>

<p>Discard all items remaining in this queue. The queue remains live and new
items can be added. The time it takes to flush will be linear to the current
queue size, and any other activity on this queue will block while it's being
flushed.</p></li>
<li><p><code>FLUSH_ALL</code></p>

<p>Discard all items remaining in all queues. The queues are flushed one at a
time, as if kestrel received a <code>FLUSH</code> command for each queue.</p></li>
<li><p><code>VERSION</code></p>

<p>Display the kestrel version in a way compatible with memcache.</p></li>
<li><p><code>SHUTDOWN</code></p>

<p>Cleanly shutdown the server and exit.</p></li>
<li><p><code>RELOAD</code></p>

<p>Reload the config file and reconfigure all queues. This should have no
noticable effect on the server's responsiveness.</p></li>
<li><p><code>STATS</code></p>

<p>Display server stats in memcache style. They're described below.</p></li>
<li><p><code>DUMP_STATS</code></p>

<p>Display server stats in a more readable style, grouped by queue. They're
described below.</p></li>
<li><p><code>MONITOR &lt;queue-name&gt; &lt;seconds&gt; [max-items]</code></p>

<p>Monitor a queue for a time, fetching any new items that arrive, up to an
optional maximum number of items. Clients are queued in a fair fashion,
per-item, so many clients may monitor a queue at once. After the given
timeout, a separate <code>END</code> response will signal the end of the monitor
period. Any fetched items are open transactions (see "Reliable Reads"
below), and should be closed with <code>CONFIRM</code>.</p></li>
<li><p><code>CONFIRM &lt;queue-name&gt; &lt;count&gt;</code></p>

<p>Confirm receipt of <code>count</code> items from a queue. Usually this is the response
to a <code>MONITOR</code> command, to confirm the items that arrived during the monitor
period.</p></li>
<li><p><code>STATUS</code></p></li>
</ul>

<p>Displays the kestrel server's current status (see section on Server Status,
below).</p>

<ul>
<li><code>STATUS &lt;new-status&gt;</code></li>
</ul>

<p>Switches the kestrel server's current status to the given status (see section
on Server Status, below).</p>

<h4>Reliable reads</h4>

<p>Note: this section is specific to the memcache protocol.</p>

<p>Normally when a client removes an item from the queue, kestrel immediately
discards the item and assumes the client has taken ownership. This isn't
always safe, because a client could crash or lose the network connection
before it gets the item. So kestrel also supports a "reliable read" that
happens in two stages, using the <code>/open</code> and <code>/close</code> options to <code>GET</code>.</p>

<p>When <code>/open</code> is used, and an item is available, kestrel will remove it from
the queue and send it to the client as usual. But it will also set the item
aside. If a client disconnects while it has an open read, the item is put back
into the queue, at the head, so it will be the next item fetched. Only one
item can be "open" per client connection.</p>

<p>A previous open request is closed with <code>/close</code>. The server will reject any
attempt to open another read when one is already open, but it will ignore
<code>/close</code> if there's no open request, so that you can add <code>/close</code> to every
<code>GET</code> request for convenience.</p>

<p>If for some reason you want to abort a read without disconnecting, you can use
<code>/abort</code>. But because aborted items are placed back at the head of the queue,
this isn't a good way to deal with client errors. Since the error-causing item
will always be the next one available, you'll end up bouncing the same item
around between clients instead of making progress.</p>

<p>There's always a trade-off: either potentially lose items or potentially
receive the same item multiple times. Reliable reads choose the latter option.
To use this tactic successfully, work items should be idempotent, meaning the
work could be done 2 or 3 times and have the same effect as if it had been
done only once (except wasting some resources).</p>

<p>Example:</p>

<pre><code>GET dirty_jobs/close/open
(receives job 1)
GET dirty_jobs/close/open
(closes job 1, receives job 2)
...etc...
</code></pre>

<h3>Text protocol</h3>

<p>Kestrel supports a limited, text-only protocol. You are encouraged to use the
memcache protocol instead.</p>

<p>The text protocol does not support reliable reads.</p>

<h2>Server Status</h2>

<p>Each kestrel server maintains its current status. Normal statuses are</p>

<ul>
<li><code>Up</code>: the server is available for all operations</li>
<li><code>ReadOnly</code>: the server is available for non-modifying operations only;
          commands that modify queues (set, delete, flush) are rejected as
      errors.</li>
<li><code>Quiescent</code>: the server rejects as an error operations on any queue. One
           notable exception is transactions begun before the server entered
       the quiesecent state may still be confirmed.</li>
</ul>

<p>One additional status is <code>Down</code>, which is only used transiently when kestrel is
in the process of shutting down.</p>

<p>The server's current status is persisted (specified in
<a href="http://robey.github.com/kestrel/api/main/api/net/lag/kestrel/config/KestrelConfig.html">KestrelConfig</a>).
When kestrel is restarted it automatically returns to it's previous status,
based on the value in the status file. If the status file does not exist or
cannot be read, kestrel uses a default status, also configured in KestrelConfig.</p>

<p>When changing from a less restrictive status to a more restrictive status
(e.g., from <code>Up</code> to <code>ReadOnly</code> or from <code>ReadOnly</code> to <code>Quiescent</code>), the
config option <code>statusChangeGracePeriod</code> determines how long kestrel will
continue to allow restricted operations to continue before it begins rejecting
them. This allows clients that are aware of the kestrel server's status a
grace period to learn the new status and cease the forbidden operations before
beginning to encounter errors.</p>

<h3>ZooKeeper Server Sets</h3>

<p>Kestrel uses Twitter's ServerSet library to support client discovery of kestrel
servers allowing a given operation. The ServerSet class is documented here:
<a href="http://twitter.github.com/commons/apidocs/index.html#com.twitter.common.zookeeper.ServerSet">ServerSet</a></p>

<p>If the optional <code>zookeeper</code> field of <code>KestrelConfig</code> is specified, kestrel will
attempt to use the given configuration to join a logical set of kestrel servers.
The ZooKeeper host, port and other connection options are documented here:
<a href="http://robey.github.com/kestrel/api/main/api/net/lag/kestrel/config/ZooKeeperBuilder.html">ZooKeeperBuilder</a></p>

<p>Kestrel servers will join 0, 1, or 2 server sets depending on their current
status. When <code>Up</code>, the server joins two server sets: one for writes and one for
reads. When <code>ReadOnly</code>, the server joins only the read set. When <code>Quiescent</code>,
the server joins no sets. ZooKeeper-aware kestrel clients can watch the
server set for changes and adjust their connections accordingly. The
<code>statusChangeGracePeriod</code> configuration option may be used to allow clients
time to detect and react to the status change before they begin receiving
errors from kestrel.</p>

<p>The ZooKeeper path used to register the server set is based on the <code>pathPrefix</code>
option. Kestrel automatically appends <code>/write</code> and <code>/read</code> to distinguish the
write and read sets.</p>

<p>Kestrel advertises all of its endpoints in each server set that it joins.
The default endpoint is memcache, if configured. The default endpoint falls
back to the thrift endpoint and then the text protocol endpoint. All three
endpoints are advertised as additional endpoints under the names <code>memcache</code>,
<code>thrift</code> and <code>text</code>.</p>

<p>Kestrel advertises only a single IP address per endpoint. This IP address is
based on Kestrel's <code>listenAddress</code>. If the listener address is the wildcard
address (e.g., <code>0.0.0.0</code> or <code>::</code>), Kestrel will advertise the first IP address
it finds by traversing the host's configured network interfaces (via
<code>java.net.NetworkInterface</code>). If your host has multiple, valid external IP
addresses you can choose the advertised address by setting the listener address
to that IP. Finally, If the listener address is a loopback address (e.g.,
<code>127.0.0.1</code> or <code>::1</code>), Kestrel will not start, since advertising a loopback
address on ZooKeeper will not work and no external host could connect to
Kestrel in any event.</p>

<p>Consider setting the  <code>defaultStatus</code> option to <code>Quiescent</code> to prevent kestrel
from prematurely advertising its status via ZooKeeper.</p>

<p>Installations that require additional customization of ZooKeeper credentials,
or other site-specific ZooKeeper initialization can override the
<code>clientInitializer</code> and <code>serverSetInitializer</code> options to invoke the
necessary site-specific code. The recommended implementation is to place
the site-specific code in its own JAR file, take the necessary steps to
include the JAR in kestrel's class path, and place as little logic as possible
in the kestrel configuration file.</p>

<h2>Server stats</h2>

<p>Global stats reported by kestrel are:</p>

<ul>
<li><code>uptime</code> - seconds the server has been online</li>
<li><code>time</code> - current time in unix epoch</li>
<li><code>version</code> - version string, like "1.2"</li>
<li><code>curr_items</code> - total of items waiting in all queues</li>
<li><code>total_itmes</code> - total of items that have ever been added in this server's
lifetime</li>
<li><code>bytes</code> - total byte size of items waiting in all queues</li>
<li><code>curr_connections</code> - current open connections from clients</li>
<li><code>total_connections</code> - total connections that have been opened in this
server's lifetime</li>
<li><code>cmd_get</code> - total <code>GET</code> requests</li>
<li><code>cmd_set</code> - total <code>SET</code> requests</li>
<li><code>cmd_peek</code> - total <code>GET/peek</code> requests</li>
<li><code>get_hits</code> - total <code>GET</code> requests that received an item</li>
<li><code>get_misses</code> - total <code>GET</code> requests on an empty queue</li>
<li><code>bytes_read</code> - total bytes read from clients</li>
<li><code>bytes_written</code> - total bytes written to clients</li>
<li><code>queue_creates</code> - total number of queues created</li>
<li><code>queue_deletes</code> - total number of queues deleted (includes expires)</li>
<li><code>queue_expires</code> - total number of queues expires</li>
</ul>

<p>For each queue, the following stats are also reported:</p>

<ul>
<li><code>items</code> - items waiting in this queue</li>
<li><code>bytes</code> - total byte size of items waiting in this queue</li>
<li><code>total_items</code> - total items that have been added to this queue in this
server's lifetime</li>
<li><code>logsize</code> - byte size of the queue's journal file</li>
<li><code>expired_items</code> - total items that have been expired from this queue in this
server's lifetime</li>
<li><code>mem_items</code> - items in this queue that are currently in memory</li>
<li><code>mem_bytes</code> - total byte size of items in this queue that are currently in
memory (will always be less than or equal to <code>max_memory_size</code> config for
the queue)</li>
<li><code>age</code> - time, in milliseconds, that the last item to be fetched from this
queue had been waiting; that is, the time between <code>SET</code> and <code>GET</code>; if the
queue is empty, this will always be zero</li>
<li><code>discarded</code> - number of items discarded because the queue was too full</li>
<li><code>waiters</code> - number of clients waiting for an item from this queue (using
<code>GET/t</code>)</li>
<li><code>open_transactions</code> - items read with <code>/open</code> but not yet confirmed</li>
<li><code>transactions</code> - number of transactional get requests (irrespective of whether an
item was read or not)</li>
<li><code>canceled_transactions</code> - number of transactional get requests canceled (for any
reason)</li>
<li><code>total_flushes</code> - total number of times this queue has been flushed</li>
<li><code>age_msec</code> - age of the last item read from the queue</li>
<li><code>create_time</code> - the time that the queue was created (in milliseconds since epoch)</li>
</ul>

<p>Statistics may be retrieved by accessing the
<a href="https://github.com/twitter/ostrich">Ostrich admin HTTP service</a> on the admin HTTP port.
For example: <code>http://kestrel.host:2223/stats.json?period=60</code>.</p>

<p>Statistics are also available via the memcache protocol using the <code>STATS</code> command.</p>

<h2>Kestrel as a library</h2>

<p>You can use kestrel as a library by just sticking the jar on your classpath.
It's a cheap way to get a durable work queue for inter-process or inter-thread
communication. Each queue is represented by a <code>PersistentQueue</code> object:</p>

<pre><code>class PersistentQueue(val name: String, persistencePath: String,
                      @volatile var config: QueueConfig, timer: Timer,
                      queueLookup: Option[(String =&gt; Option[PersistentQueue])]) {
</code></pre>

<p>and must be initialized before using:</p>

<pre><code>def setup(): Unit
</code></pre>

<p>specifying the path for the journal files (if the queue will be journaled),
the name of the queue, a <code>QueueConfig</code> object (derived from <code>QueueBuilder</code>),
a timer for handling timeout reads, and optionally a way to find other named
queues (for <code>expireToQueue</code> support).</p>

<p>To add an item to a queue:</p>

<pre><code>def add(value: Array[Byte], expiry: Option[Time]): Boolean
</code></pre>

<p>It will return <code>false</code> if the item was rejected because the queue was full.</p>

<p>Queue items are represented by a case class:</p>

<pre><code>case class QItem(addTime: Time, expiry: Option[Time], data: Array[Byte], var xid: Int)
</code></pre>

<p>and several operations exist to remove or peek at the head item:</p>

<pre><code>def peek(): Option[QItem]
def remove(): Option[QItem]
</code></pre>

<p>To open a reliable read, set <code>transaction</code> true, and later confirm or unremove
the item by its <code>xid</code>:</p>

<pre><code>def remove(transaction: Boolean): Option[QItem]
def unremove(xid: Int)
def confirmRemove(xid: Int)
</code></pre>

<p>You can also asynchronously remove or peek at items using futures.</p>

<pre><code>def waitRemove(deadline: Option[Time], transaction: Boolean): Future[Option[QItem]]
def waitPeek(deadline: Option[Time]): Future[Option[QItem]]
</code></pre>

<p>When done, you should close the queue:</p>

<pre><code>def close(): Unit
def isClosed: Boolean
</code></pre>

<p>Here's a short example:</p>

<pre><code>var queue = new PersistentQueue("work", "/var/spool/kestrel", config, timer, None)
queue.setup()

// add an item with no expiration:
queue.add("hello".getBytes, 0)

// start to remove it, then back out:
val item = queue.remove(true)
queue.unremove(item.xid)

// remove an item with a 500msec timeout, and confirm it:
queue.waitRemove(500.milliseconds.fromNow, true)() match {
  case None =&gt;
    println("nothing. :(")
  case Some(item) =&gt;
    println("got: " + new String(item.data))
    queue.confirmRemove(item.xid)
}

queue.close()
</code></pre>


</body>
</html>
